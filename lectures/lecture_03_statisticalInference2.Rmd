---
title: "Statistical inference 2"
author: "Daniel Hammarstr√∂m"
date: "14 10 2019"
output: beamer_presentation
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```


# Measures of dispersion

- The sample variance is a **estimate** of the population variance.
- We use the degrees of freedom, $n-1$ as denominator instead of $n$, why?
- There are $n-1$ values that can vary, if we know the deviations of $n-1$ we can calculate the last value.

# Degrees of freedom leading to unbiased estimation of variance

```{r, message=FALSE, warning=FALSE, echo = FALSE}

pop.var <- population %>%
        mutate(Xbar = mean(pop), 
               X_xbar = pop - Xbar,
               X_xbar_squared = X_xbar^2) %>%
        summarise(population.variance = sum(X_xbar_squared)/n()) %>%
        as.numeric()
        

results <- data.frame(biased = rep(NA, 30), 
                      unbiased = rep(NA, 30))

for(i in 1:300) {
        
        samp <- sample(population$pop, 15, replace = FALSE)
        
        biased <- sum((samp - mean(samp))^2) / 15
        unbiased <- sum((samp - mean(samp))^2) / 14
        
        results[i, 1] <- biased; results[i, 2] <- unbiased
        }

est.var <- results %>%
        gather(estimate, variance, biased:unbiased) %>%
        group_by(estimate) %>%
        summarise(mean = mean(variance))
```

* We can explore the effect of $n-1$ in the estimation of variance using simulations

* If the population ($N = 1000000$) has a variance of `r round(pop.var, 2)`, repeated sampling using a small sample size ($n=15$) using $n$ as denominator resulted in an average variance of around `r round(as.numeric(est.var[1,2]), 2)`.

* Using $n-1$ as denominator resulted in an average variance around `r round(as.numeric(est.var[2,2]), 2)`.

* $n-1$ is really useful in situations with small $n$, it produces an **unbiased estimate of the population parameter**.

# Variance and the standard deviation

* The variance is the average squared deviation from the mean
* The standard deviation is the square root of the variance, thus on the same scale as the mean

$$\sqrt{\frac{\sum{(x_i-\bar{x})^2}}{n-1}} = SD$$





# The confidence interval

* We can use the fact that we can estimate the variation in the sampling distribution and create a confidence interval. 
* **The 95% confidence interval**: *If we construct many confidence intervals using independent samples, 95% of the intervals will contain the population parameter*.

# The confidence interval

```{r, echo = FALSE, warning=FALSE, message=FALSE}

df <- data.frame(ciu.5 = rep(NA, 2),
                 cil.5 = rep(NA, 2),
                 ciu.30 = rep(NA, 2),
                 cil.30 = rep(NA, 2))

set.seed(4)
for(i in 1:1000) {
        
        
        samp.5 <- sample(population$pop, 5, replace = FALSE)
        samp.30 <- sample(population$pop, 30, replace = FALSE)
        
     df[i,1] <- mean(samp.5) + qt(0.975, df = 4) * sd(samp.5)/sqrt(5)
     df[i,2] <- mean(samp.5) - qt(0.975, df = 4)*sd(samp.5)/sqrt(5) 
     df[i,3] <- mean(samp.30) + qt(0.975, df = 29)*sd(samp.30)/sqrt(30)
     df[i,4] <- mean(samp.30) - qt(0.975, df = 29)*sd(samp.30)/sqrt(30)
        
}

df2 <- df %>%
        mutate(coverage.5 = if_else(ciu.5> mean(population$pop) & cil.5 < mean(population$pop), "cover", "no.cover"),
               coverage.30 = if_else(ciu.30> mean(population$pop) & cil.30 < mean(population$pop), "cover", "no.cover"),) 


c5 <- df2 %>%
        mutate(interval = seq(from = 1, to = 1000), 
               coverage.5 = factor(coverage.5, labels = c("Contain parameter", "Do not contain\nparameter"))) %>%
        top_n(100) %>%
        ggplot(aes(interval, color = coverage.5)) + 
        geom_hline(yintercept = 100) +
        geom_errorbar(aes(ymax = ciu.5, ymin = cil.5)) +
        scale_color_manual(values = c("black", "red"), name = "Sample size = 5") + 
        scale_y_continuous(limits = c(70, 130), expand = c(0,0)) +
        theme_minimal() + 
        theme(axis.title.x = element_blank(),
              axis.text.x = element_blank())

c30 <- df2 %>%
        mutate(interval = seq(from = 1, to = 1000), 
               coverage.30 = factor(coverage.30, labels = c("Contain parameter", "Do not contain\nparameter"))) %>%
        top_n(100) %>%
        ggplot(aes(interval, color = coverage.30)) + 
        geom_hline(yintercept = 100) +
        geom_errorbar(aes(ymax = ciu.30, ymin = cil.30)) +
        scale_color_manual(values = c("black", "red"), name = "Sample size = 30") + 
        scale_y_continuous(limits = c(70, 130), expand = c(0,0)) +
        theme_minimal() + 
        theme(axis.title.x = element_blank(),
              axis.text.x = element_blank())

library(cowplot)

plot_grid(c5, c30, ncol = 1)

```


# Hypothesis testing 

* Based on the estimate of the sampling distribution we can device a test, to test if a value exists within specified range. 
* 95% of all values lies within $\pm 1.96\times \sigma$ from the mean in a normal distribution, this leaves us with an uncertainty of 5%.
* However, due to problems with *proving a theory or hypothesis*, we instead test against a null-hypothesis. Thus we try to *disprove the hypothesis*.


* The null hypothesis $H_0$ is constructed to contain scenarios not covered by the alternative hypothesis $H_A$

# Hypothesis tests - a two sample scenario

* The null hypothesis is that the mean of group 1 is similar to group 2

$$H_0: \mu_1 - \mu_2 = 0$$

* To reject this hypothesis, we need to show that

$$\mu_1 - \mu_2 \neq 0$$

* We want to do this with some specified uncertainty, usually 5%

* We can calculate a 95% confidence interval of the difference 

# A 95% confidence interval for small samples

Upper bound: $$\bar{x} + t_{1-\alpha/2} \times SE$$
Lower bound: $$\bar{x} - t_{1-\alpha/2} \times SE$$

* $\bar{x}$ is the difference in means between groups.
* The standard error ($SE$) estimates the standard deviation of the sampling distribution
* $t_{1-\alpha/2}$ represents the area under probability distribution curve containing 95% of all values.
* The $t$-distribution is used instead of the normal distribution since it can take sample-size into account. 

# The t-distribution

```{r, message = FALSE, warning=FALSE, echo=FALSE}

# The code was grabbed from https://www.statmethods.net/advgraphs/probability.html

x <- seq(-4, 4, length=100)
hx <- dnorm(x)

degf <- c(1, 3, 8, 30)
colors <- c("red", "blue", "darkgreen", "gold", "black")
labels <- c("df=1", "df=3", "df=8", "df=30", "normal")

plot(x, hx, type="l", lty=2, xlab="x value",
  ylab="Density", main="Comparison of t Distributions")

for (i in 1:4){
  lines(x, dt(x,degf[i]), lwd=2, col=colors[i])
}

legend("topright", inset=.05, title="Distributions",
  labels, lwd=2, lty=c(1, 1, 1, 1, 2), col=colors)


```

# A two sample case

```{r, message = FALSE, warning=FALSE, echo=FALSE, fig.height=4, fig.width=4}
set.seed(1)
df <- data.frame(G1 = rnorm(30, 12, 1.2), G2 = rnorm(30, 12.9, 1.3))
df %>%
        gather(group, value, G1:G2) %>%
        ggplot(aes(group, value)) + geom_boxplot() + theme_minimal() +
        xlab("Group") + ylab("Value")


# Pooled standard deviation

# mean difference

m <- mean(df$G2) - mean(df$G1)

se <- sqrt(((sd(df$G1)^2)/30) + (((sd(df$G2)^2)/30)))

ciu <- m + se * qt(0.975, 30 + 30 -2)
cil <- m - se * qt(0.975, 30 + 30 -2)
```

# A 95% confidence of the difference in means

* Two groups are compared, the $H_0$ is that there is no difference between the groups:

$$H_0: \mu_1 = \mu_2$$

* The difference between the groups are estimated to $\mu_2 - \mu_1 =$ `r round(m, 2)`
* The 95% confidence interval is 
$$m_2 - m_1 \pm t_{\alpha/2} \times SE(m_2 - m_1)$$ 
where the $$SE(m_2 - m_1)$$ is the standard error of the difference. 

$$0.97 \pm 2 \times 0.28$$


# Key points so far

* We can *estimate* population *parameters* using a **random** sample from the population
* The calculated sample standard error is an estimate of the standard deviation of a sampling distribution
* Using a *probability density function* like the $t$- or $z$-distribution, we can estimate a range a plausible values of a population parameter (e.g. mean).
* We can test if a estimated interval contains the null hypothesis, if not we can reject $H_0$.


# Alternative to the confidence interval

* Instead of a confidence interval, we can calculate a $t$ statistic
* This tells us how far from the null hypothesis our observed value is, if this value is larger than a *critical value* (usually corresponding to <5% of all possible values) we declare the statistic as *significant*
* This is the basis of the $t$-test.

# Hypothesis testing

* We have now performed hypothesis testing about the difference between two groups
* Using the estimation of the standard deviation of the sampling distribution we calculated an interval that upon repeated sampling would contain the true parameter 95 of 100 times.
* We can with some (acceptable) uncertainty reject (or not) the null hypothesis.
* This is the general principle of hypothesis testing, an interval of the test statistic is constructed based on an appropriate probability distribution


# The t-test

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.align="center", fig.height=4, fig.width=4}

xvalues <- data.frame(x = c(-3, 3))


shade.area.u <- function(x){
        norm_two_sd <- dt(x, df = 30)
        # Have NA values outside interval x in [-2, 2]:
        norm_two_sd[x <=  qt(0.975, df = 30)| x >= 5] <- NA
        return(norm_two_sd)
}

shade.area.l <- function(x){
        norm_two_sd <- dt(x, df = 30)
        # Have NA values outside interval x in [-2, 2]:
        norm_two_sd[x <=  -5| x >= -qt(0.975, df = 30)] <- NA
        return(norm_two_sd)
}


ggplot(xvalues, aes(x = x)) + 
        stat_function(fun = dt, args = list(df = 30)) +
        stat_function(fun = shade.area.u, geom = "area", fill = "lightblue", alpha = 0.3) + 
        stat_function(fun = shade.area.l, geom = "area", fill = "lightblue", alpha = 0.3) + 
        xlab("t-value") + ylab("Density") + theme_minimal() +
        ggtitle("t-distribution", subtitle = "df = 30, critical t = 2.04") 


```

# t-test in R

```{r, eval = FALSE}
# Single-population t-test
t.test(x, mu = 0)

# Two populations t-test
t.test(x1, x2)

# Paired samples t-test
t.test(x1, x2, paired = TRUE)
```

* `mu` is value of the null-hypothesis
* `x`, `x1` and `x2` represents vectors of values
* `paired = TRUE` is used to tell R that the data is dependent

# Assumptions of the t-tests

* Normally distributed data
* Equal variance
* Independence


